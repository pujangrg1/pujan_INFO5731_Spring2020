{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pujangrg1/pujan_INFO5731_Spring2020/blob/main/In_class_exercise_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW9bNDXEV8Bu"
      },
      "source": [
        "# **The seventh in-class-exercise (20 points in total, 3/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMRgqDNtV8Bw"
      },
      "source": [
        "Question description: In the last in-class-exercise (exercise-06), you collected the titles of 100 articles about data science, natural language processing, and machine learning. The 100 article titles will be used as the text corpus of this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByKHtHOJV8Bx"
      },
      "source": [
        "## (1) (8 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbyKbjxiV8Bz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a6db8648-1475-464f-9264-d8aa980eb560"
      },
      "source": [
        "# Write your code here\n",
        "import csv\n",
        "import pandas as pd\n",
        "file = []\n",
        "articleTitles = pd.read_csv('articleList.csv', encoding = \"ISO-8859-1\")\n",
        "articleTitles"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Data science in action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Data science and prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Data science and its relationship to big data ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[BOOK][B] Data Science for Business: What you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[BOOK][B] High-dimensional probability: An int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Computational optimal transport: With applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Data science, predictive analytics, and big da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>Reproducible, interactive, scalable and extens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>The quantified self: Fundamental disruption in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>[HTML][HTML] Big data: astronomical or genomical?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0                                              Title\n",
              "0            0                             Data science in action\n",
              "1            1                        Data science and prediction\n",
              "2            2  Data science and its relationship to big data ...\n",
              "3            3  [BOOK][B] Data Science for Business: What you ...\n",
              "4            4  [BOOK][B] High-dimensional probability: An int...\n",
              "..         ...                                                ...\n",
              "95          95  Computational optimal transport: With applicat...\n",
              "96          96  Data science, predictive analytics, and big da...\n",
              "97          97  Reproducible, interactive, scalable and extens...\n",
              "98          98  The quantified self: Fundamental disruption in...\n",
              "99          99  [HTML][HTML] Big data: astronomical or genomical?\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwPdFny_w-YA",
        "outputId": "61ebc2f3-b96b-48b0-cd7d-4a5c26b83798"
      },
      "source": [
        "# Run in python console\n",
        "import nltk; nltk.download('stopwords')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBtpl1WLxMj8",
        "outputId": "1550cf29-9a5d-4a41-a72e-287ddddd5185"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.36.2)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0; python_version > \"3.5\" in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0; python_version > \"3.5\"->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0; python_version > \"3.5\"->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0; python_version > \"3.5\"->pyLDAvis) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J00dRCWNc7d",
        "outputId": "d9274974-6157-4a74-f6b3-5c9edc3c17e3"
      },
      "source": [
        "import os\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "  !java -version\n",
        "install_java()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO9NQVWINsCc",
        "outputId": "59350f83-9948-4fcb-f35c-d525be98d930"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.7/dist-packages (3.8.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9bSq3W8N42I",
        "outputId": "c0895849-0400-4e28-a160-f850f71f31d5"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUQ1yVYfxEch"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3X4OBwRxVAj"
      },
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Ua20NIJRv4ie",
        "outputId": "e7df550d-d54e-4e61-f43f-2f01503850a3"
      },
      "source": [
        "article_titles = pd.read_csv('/content/articleList.csv', encoding = \"ISO-8859-1\")\n",
        "article_titles.head(10)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Data science in action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Data science and prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Data science and its relationship to big data ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[BOOK][B] Data Science for Business: What you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[BOOK][B] High-dimensional probability: An int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Computational optimal transport: With applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Data science, predictive analytics, and big da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Reproducible, interactive, scalable and extens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>The quantified self: Fundamental disruption in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>[HTML][HTML] Big data: astronomical or genomical?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                              Title\n",
              "0           0                             Data science in action\n",
              "1           1                        Data science and prediction\n",
              "2           2  Data science and its relationship to big data ...\n",
              "3           3  [BOOK][B] Data Science for Business: What you ...\n",
              "4           4  [BOOK][B] High-dimensional probability: An int...\n",
              "5           5  Computational optimal transport: With applicat...\n",
              "6           6  Data science, predictive analytics, and big da...\n",
              "7           7  Reproducible, interactive, scalable and extens...\n",
              "8           8  The quantified self: Fundamental disruption in...\n",
              "9           9  [HTML][HTML] Big data: astronomical or genomical?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfsW5OWfY7L2"
      },
      "source": [
        "data = article_titles['Title'].tolist()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXVWBJh5woI6",
        "outputId": "294d8019-6772-410a-874f-bfa7dd750d65"
      },
      "source": [
        "#Tokenizing words and cleaning up text using Gensim's simple_preprocess()\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical'], ['data', 'science', 'in', 'action'], ['data', 'science', 'and', 'prediction'], ['data', 'science', 'and', 'its', 'relationship', 'to', 'big', 'data', 'and', 'data', 'driven', 'decision', 'making'], ['book', 'data', 'science', 'for', 'business', 'what', 'you', 'need', 'to', 'know', 'about', 'data', 'mining', 'and', 'data', 'analytic', 'thinking'], ['book', 'high', 'dimensional', 'probability', 'an', 'introduction', 'with', 'applications', 'in', 'data', 'science'], ['computational', 'optimal', 'transport', 'with', 'applications', 'to', 'data', 'science'], ['data', 'science', 'predictive', 'analytics', 'and', 'big', 'data', 'revolution', 'that', 'will', 'transform', 'supply', 'chain', 'design', 'and', 'management'], ['reproducible', 'interactive', 'scalable', 'and', 'extensible', 'microbiome', 'data', 'science', 'using', 'qiime'], ['the', 'quantified', 'self', 'fundamental', 'disruption', 'in', 'big', 'data', 'science', 'and', 'biological', 'discovery'], ['html', 'html', 'big', 'data', 'astronomical', 'or', 'genomical']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MY8cP2x2_h"
      },
      "source": [
        "#Creating Bigram and Trigram Models\n",
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxspoGDyWMG"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyKxpGLywWF",
        "outputId": "a224cc3f-0a88-4567-cf15-f71fc4f779a3"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], [], ['datum', 'science', 'action'], ['datum', 'science', 'prediction'], ['datum', 'science', 'relationship', 'big', 'datum', 'datum', 'drive', 'decision', 'making'], ['science', 'business', 'nee', 'know', 'datum', 'mining', 'datum', 'analytic', 'thinking'], ['high', 'dimensional', 'probability', 'introduction', 'application', 'datum', 'science'], ['transport', 'application', 'datum', 'science'], ['predictive', 'analytic', 'datum', 'revolution', 'transform', 'supply', 'chain', 'design', 'management'], ['scalable', 'extensible', 'datum', 'science', 'use'], ['quantified', 'self', 'fundamental', 'science', 'biological', 'discovery'], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4xKNEDcy4iX",
        "outputId": "550432cc-fe34-41c7-ec76-118f29b5a528"
      },
      "source": [
        "#Create the Dictionary and Corpus needed for Topic Modeling\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfllTv35zTC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe23358a-aa27-4a48-da00-da862c582587"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('action', 1), ('datum', 1), ('science', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXbrw0raU_iB"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pipCcl7iVB6X",
        "outputId": "064869ff-5b3e-466e-de6b-20ae3f79c21f"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.089*\"datum\" + 0.067*\"science\" + 0.031*\"nee\" + 0.031*\"mining\" + '\n",
            "  '0.031*\"transport\" + 0.031*\"application\" + 0.031*\"thinking\" + '\n",
            "  '0.031*\"analytic\" + 0.031*\"business\" + 0.031*\"prediction\"'),\n",
            " (1,\n",
            "  '0.218*\"datum\" + 0.109*\"analytic\" + 0.109*\"thinking\" + 0.109*\"know\" + '\n",
            "  '0.109*\"business\" + 0.109*\"mining\" + 0.109*\"science\" + 0.109*\"nee\" + '\n",
            "  '0.001*\"supply\" + 0.001*\"transform\"'),\n",
            " (2,\n",
            "  '0.052*\"datum\" + 0.039*\"science\" + 0.030*\"mining\" + 0.030*\"drive\" + '\n",
            "  '0.030*\"know\" + 0.030*\"relationship\" + 0.030*\"making\" + 0.030*\"decision\" + '\n",
            "  '0.030*\"nee\" + 0.030*\"thinking\"'),\n",
            " (3,\n",
            "  '0.067*\"datum\" + 0.047*\"science\" + 0.034*\"relationship\" + 0.034*\"decision\" + '\n",
            "  '0.034*\"drive\" + 0.034*\"big\" + 0.034*\"making\" + 0.032*\"transport\" + '\n",
            "  '0.032*\"application\" + 0.028*\"action\"'),\n",
            " (4,\n",
            "  '0.162*\"science\" + 0.162*\"self\" + 0.162*\"biological\" + 0.162*\"quantified\" + '\n",
            "  '0.162*\"fundamental\" + 0.162*\"discovery\" + 0.001*\"datum\" + 0.001*\"analytic\" '\n",
            "  '+ 0.001*\"revolution\" + 0.001*\"predictive\"'),\n",
            " (5,\n",
            "  '0.315*\"science\" + 0.315*\"datum\" + 0.314*\"action\" + 0.002*\"scalable\" + '\n",
            "  '0.002*\"use\" + 0.002*\"extensible\" + 0.002*\"dimensional\" + '\n",
            "  '0.002*\"introduction\" + 0.002*\"application\" + 0.002*\"high\"'),\n",
            " (6,\n",
            "  '0.040*\"datum\" + 0.040*\"science\" + 0.034*\"prediction\" + 0.031*\"application\" '\n",
            "  '+ 0.031*\"transport\" + 0.027*\"supply\" + 0.027*\"design\" + 0.027*\"management\" '\n",
            "  '+ 0.027*\"predictive\" + 0.027*\"revolution\"'),\n",
            " (7,\n",
            "  '0.194*\"use\" + 0.194*\"scalable\" + 0.194*\"extensible\" + 0.194*\"datum\" + '\n",
            "  '0.194*\"science\" + 0.001*\"management\" + 0.001*\"design\" + 0.001*\"revolution\" '\n",
            "  '+ 0.001*\"chain\" + 0.001*\"transform\"'),\n",
            " (8,\n",
            "  '0.028*\"transform\" + 0.028*\"extensible\" + 0.028*\"chain\" + 0.028*\"design\" + '\n",
            "  '0.028*\"management\" + 0.028*\"predictive\" + 0.028*\"revolution\" + '\n",
            "  '0.028*\"supply\" + 0.028*\"probability\" + 0.028*\"biological\"'),\n",
            " (9,\n",
            "  '0.240*\"datum\" + 0.240*\"science\" + 0.240*\"application\" + 0.239*\"transport\" + '\n",
            "  '0.001*\"drive\" + 0.001*\"probability\" + 0.001*\"relationship\" + '\n",
            "  '0.001*\"introduction\" + 0.001*\"big\" + 0.001*\"making\"'),\n",
            " (10,\n",
            "  '0.327*\"datum\" + 0.110*\"science\" + 0.109*\"drive\" + 0.109*\"big\" + '\n",
            "  '0.109*\"decision\" + 0.109*\"making\" + 0.109*\"relationship\" + '\n",
            "  '0.001*\"transport\" + 0.001*\"prediction\" + 0.001*\"application\"'),\n",
            " (11,\n",
            "  '0.028*\"transform\" + 0.028*\"extensible\" + 0.028*\"chain\" + 0.028*\"design\" + '\n",
            "  '0.028*\"management\" + 0.028*\"predictive\" + 0.028*\"revolution\" + '\n",
            "  '0.028*\"supply\" + 0.028*\"probability\" + 0.028*\"biological\"'),\n",
            " (12,\n",
            "  '0.140*\"datum\" + 0.140*\"science\" + 0.140*\"introduction\" + 0.140*\"high\" + '\n",
            "  '0.140*\"application\" + 0.140*\"probability\" + 0.140*\"dimensional\" + '\n",
            "  '0.001*\"transform\" + 0.001*\"predictive\" + 0.001*\"supply\"'),\n",
            " (13,\n",
            "  '0.044*\"datum\" + 0.035*\"science\" + 0.030*\"big\" + 0.030*\"relationship\" + '\n",
            "  '0.030*\"application\" + 0.030*\"introduction\" + 0.030*\"making\" + 0.030*\"drive\" '\n",
            "  '+ 0.030*\"dimensional\" + 0.030*\"decision\"'),\n",
            " (14,\n",
            "  '0.048*\"science\" + 0.048*\"datum\" + 0.043*\"action\" + 0.029*\"chain\" + '\n",
            "  '0.029*\"quantified\" + 0.029*\"revolution\" + 0.029*\"management\" + '\n",
            "  '0.029*\"fundamental\" + 0.029*\"biological\" + 0.029*\"supply\"'),\n",
            " (15,\n",
            "  '0.075*\"datum\" + 0.056*\"science\" + 0.033*\"dimensional\" + 0.033*\"probability\" '\n",
            "  '+ 0.033*\"high\" + 0.033*\"application\" + 0.033*\"introduction\" + 0.029*\"drive\" '\n",
            "  '+ 0.029*\"big\" + 0.029*\"decision\"'),\n",
            " (16,\n",
            "  '0.316*\"prediction\" + 0.316*\"science\" + 0.316*\"datum\" + 0.002*\"transform\" + '\n",
            "  '0.002*\"scalable\" + 0.002*\"design\" + 0.002*\"management\" + 0.002*\"predictive\" '\n",
            "  '+ 0.002*\"revolution\" + 0.002*\"supply\"'),\n",
            " (17,\n",
            "  '0.109*\"analytic\" + 0.109*\"datum\" + 0.109*\"chain\" + 0.109*\"design\" + '\n",
            "  '0.109*\"management\" + 0.109*\"predictive\" + 0.109*\"revolution\" + '\n",
            "  '0.109*\"transform\" + 0.109*\"supply\" + 0.001*\"transport\"'),\n",
            " (18,\n",
            "  '0.068*\"datum\" + 0.067*\"science\" + 0.037*\"extensible\" + 0.037*\"scalable\" + '\n",
            "  '0.037*\"use\" + 0.034*\"quantified\" + 0.034*\"fundamental\" + 0.034*\"self\" + '\n",
            "  '0.034*\"biological\" + 0.034*\"discovery\"'),\n",
            " (19,\n",
            "  '0.035*\"predictive\" + 0.035*\"revolution\" + 0.035*\"management\" + '\n",
            "  '0.035*\"supply\" + 0.035*\"transform\" + 0.035*\"analytic\" + 0.035*\"design\" + '\n",
            "  '0.035*\"chain\" + 0.035*\"datum\" + 0.026*\"transport\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0UoltUTV8B0"
      },
      "source": [
        "## (2) (8 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtxUqE-yvdY"
      },
      "source": [
        "#import modules\n",
        "import os.path\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlM7OESOq0vq"
      },
      "source": [
        "**Create an LSA model using Gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUTEP2XWV8B3"
      },
      "source": [
        "# Write your code here\n",
        "lsamodel = LsiModel(corpus, 20, id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwe3v8X3sH8d"
      },
      "source": [
        "**Determine the number of topics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ku6394sB_4"
      },
      "source": [
        "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, stop, step):\n",
        "        # generate LSA model\n",
        "        model = LsiModel(doc_term_matrix, num_topics=20, id2word = dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mvs3XTqshhy"
      },
      "source": [
        "**Coherence score values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPz81I2Xsk3C"
      },
      "source": [
        "start,stop,step=2,60,6\n",
        "model_list_lsa, coherence_values_lsa = compute_coherence_values(id2word, corpus,data_lemmatized,stop, start, step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRYRBoHSu-Kd",
        "outputId": "569ee161-0743-4348-bf03-76e4fe50756f"
      },
      "source": [
        "for no_of_topics, cv in zip(range(2, 60, 6), coherence_values_lsa):\n",
        "  print(\"Num Topics:\", no_of_topics, \" - Coherence Value:\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics: 2  - Coherence Value: 0.4226\n",
            "Num Topics: 8  - Coherence Value: 0.4122\n",
            "Num Topics: 14  - Coherence Value: 0.4348\n",
            "Num Topics: 20  - Coherence Value: 0.4817\n",
            "Num Topics: 26  - Coherence Value: 0.4297\n",
            "Num Topics: 32  - Coherence Value: 0.4469\n",
            "Num Topics: 38  - Coherence Value: 0.4451\n",
            "Num Topics: 44  - Coherence Value: 0.423\n",
            "Num Topics: 50  - Coherence Value: 0.4523\n",
            "Num Topics: 56  - Coherence Value: 0.4326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp40OCYdvSpO"
      },
      "source": [
        "**Print Topics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn8Paf8fvfAi",
        "outputId": "d6fdb462-99a8-43a2-93fe-474c94c0cfbc"
      },
      "source": [
        "pprint(lsamodel.print_topics())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.792*\"datum\" + 0.453*\"science\" + 0.128*\"analytic\" + 0.115*\"making\" + '\n",
            "  '0.115*\"relationship\" + 0.115*\"decision\" + 0.115*\"drive\" + 0.115*\"big\" + '\n",
            "  '0.099*\"application\" + 0.088*\"thinking\"'),\n",
            " (1,\n",
            "  '0.357*\"analytic\" + -0.319*\"science\" + 0.303*\"transform\" + 0.303*\"design\" + '\n",
            "  '0.303*\"management\" + 0.303*\"predictive\" + 0.303*\"revolution\" + '\n",
            "  '0.303*\"chain\" + 0.303*\"supply\" + -0.139*\"application\"'),\n",
            " (2,\n",
            "  '0.347*\"science\" + 0.255*\"discovery\" + 0.255*\"self\" + 0.255*\"fundamental\" + '\n",
            "  '0.255*\"quantified\" + 0.255*\"biological\" + -0.232*\"drive\" + '\n",
            "  '-0.232*\"decision\" + -0.232*\"relationship\" + -0.232*\"making\"'),\n",
            " (3,\n",
            "  '-0.351*\"mining\" + -0.351*\"know\" + -0.351*\"business\" + -0.351*\"thinking\" + '\n",
            "  '-0.351*\"nee\" + -0.218*\"analytic\" + 0.202*\"application\" + 0.151*\"high\" + '\n",
            "  '0.151*\"dimensional\" + 0.151*\"introduction\"'),\n",
            " (4,\n",
            "  '0.359*\"application\" + -0.291*\"fundamental\" + -0.291*\"self\" + '\n",
            "  '-0.291*\"discovery\" + -0.291*\"quantified\" + -0.291*\"biological\" + '\n",
            "  '0.281*\"probability\" + 0.281*\"introduction\" + 0.281*\"dimensional\" + '\n",
            "  '0.281*\"high\"'),\n",
            " (5,\n",
            "  '0.470*\"use\" + 0.470*\"extensible\" + 0.470*\"scalable\" + 0.193*\"science\" + '\n",
            "  '-0.145*\"introduction\" + -0.145*\"probability\" + -0.145*\"dimensional\" + '\n",
            "  '-0.145*\"high\" + -0.124*\"drive\" + -0.124*\"making\"'),\n",
            " (6,\n",
            "  '0.477*\"transport\" + -0.255*\"use\" + -0.255*\"scalable\" + -0.255*\"extensible\" '\n",
            "  '+ 0.248*\"prediction\" + 0.248*\"action\" + -0.244*\"introduction\" + '\n",
            "  '-0.244*\"dimensional\" + -0.244*\"probability\" + -0.244*\"high\"'),\n",
            " (7,\n",
            "  '0.514*\"transport\" + -0.445*\"prediction\" + -0.445*\"action\" + '\n",
            "  '0.425*\"application\" + -0.169*\"science\" + 0.127*\"use\" + 0.127*\"extensible\" + '\n",
            "  '0.127*\"scalable\" + -0.089*\"probability\" + -0.089*\"dimensional\"'),\n",
            " (8,\n",
            "  '-0.707*\"action\" + 0.707*\"prediction\" + 0.000*\"transport\" + '\n",
            "  '-0.000*\"relationship\" + 0.000*\"analytic\" + 0.000*\"science\" + 0.000*\"big\" + '\n",
            "  '-0.000*\"thinking\" + -0.000*\"transform\" + 0.000*\"chain\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXxAmKREV8B3"
      },
      "source": [
        "## (3) (4 points) Compare the results generated by the two topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w155r991UFBV"
      },
      "source": [
        "Each of the two modeling algorithms has had varying degrees of success. With LDA, i was able to generate 20 topics where as with LSA outputed only 10 topics. LSA generated a more coherent topic-set and a more reasonable topic distribution. LDA achieved nearly the opposite: separation between topics was very good, but the topics derived were not especially intelligible, and their distribution seemed unlikely.\n",
        "But regardless, the above explorations establish a strong foundation for any further analyses of the dataset – and moreover, clearly demonstrate the viability of topic modelling on an ostensibly novel data format."
      ]
    }
  ]
}